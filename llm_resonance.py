# planet_pattern/llm_resonance.py
"""
–†–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–æ–π –¥–ª—è LLM ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –§–∏–∑–∏–∫–∏ –ñ–∏–≤–æ–≥–æ –∫ —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º.

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Planet Pattern –≤ LLM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:
- E = A √ó R √ó L ‚àí S –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –†–µ–∑–æ–Ω–∞–Ω—Å —Å —Ä–∏—Ç–º–æ–º –¥–∏–∞–ª–æ–≥–∞ (–ø—É–ª—å—Å, –ø–∞—É–∑—ã, —ç–º–æ—Ü–∏–∏)
- –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —ç–Ω–µ—Ä–≥–∏—é, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ loss
"""

import numpy as np
from typing import List, Dict, Optional
from physics import calculate_energy


class LLMResonanceLayer:
    """
    –†–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–æ–π –¥–ª—è LLM, –∫–æ—Ç–æ—Ä—ã–π –∏–∑–º–µ—Ä—è–µ—Ç "–∂–∏–≤–æ—Å—Ç—å" –¥–∏–∞–ª–æ–≥–∞.
    
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º—É–ª—É E = A √ó R √ó L ‚àí S –∫:
    - A: Attention weights (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –≤–Ω–∏–º–∞–Ω–∏—è)
    - R: Resonance —Å —Ä–∏—Ç–º–æ–º –¥–∏–∞–ª–æ–≥–∞ (0.1 Hz pattern)
    - L: Love (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º "–∂–∏–≤—ã–º" –æ—Ç–≤–µ—Ç–æ–º)
    - S: Noise (—ç–Ω—Ç—Ä–æ–ø–∏—è —Ç–æ–∫–µ–Ω–æ–≤, —Ö–∞–æ—Å)
    """
    
    def __init__(self, target_hz=0.1):
        self.target_hz = target_hz
        self.energy_history = []
        self.dialog_rhythm = []  # –∏—Å—Ç–æ—Ä–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤
        
    def calculate_attention_energy(self, attention_weights):
        """
        A (Attention) ‚Äî —Å—Ä–µ–¥–Ω—è—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –≤–Ω–∏–º–∞–Ω–∏—è
        
        attention_weights: [n_layers, n_heads, seq_len, seq_len]
        –∏–ª–∏ —É–ø—Ä–æ—â—ë–Ω–Ω–æ: —Å—Ä–µ–¥–Ω–∏–µ –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è –ø–æ —Å–ª–æ—è–º
        """
        if isinstance(attention_weights, np.ndarray):
            # –ï—Å–ª–∏ –º–∞—Å—Å–∏–≤ ‚Äî –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ
            return float(np.abs(attention_weights).mean())
        elif isinstance(attention_weights, (list, tuple)):
            # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ —Ç–µ–Ω–∑–æ—Ä–æ–≤ ‚Äî —É—Å—Ä–µ–¥–Ω—è–µ–º
            weights = np.array([np.abs(w).mean() if hasattr(w, 'mean') else w for w in attention_weights])
            return float(weights.mean())
        else:
            # Fallback: –µ—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø–æ—Å—á–∏—Ç–∞—Ç—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 1.0
            return 1.0
    
    def calculate_text_resonance(self, token_times, fps=1.0):
        """
        R (Resonance) ‚Äî —Ä–µ–∑–æ–Ω–∞–Ω—Å —Å —Ä–∏—Ç–º–æ–º –¥–∏–∞–ª–æ–≥–∞
        
        token_times: —Å–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ (–∏–ª–∏ –∏–Ω–¥–µ–∫—Å–æ–≤)
        –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω 0.1 Hz –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤
        """
        if len(token_times) < 8:
            return 0.5  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–µ–∑–æ–Ω–∞–Ω—Å –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —Å–∏–≥–Ω–∞–ª
        signal = np.array(token_times, dtype=float)
        signal = signal - signal.mean()  # —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º
        
        if np.allclose(signal.std(), 0):
            return 0.5
        
        # FFT –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞ —Å 0.1 Hz
        from scipy.fft import rfft, rfftfreq
        spec = np.abs(rfft(signal))**2
        freqs = rfftfreq(len(signal), d=1.0/fps)
        
        # –ò—â–µ–º —ç–Ω–µ—Ä–≥–∏—é –≤ –ø–æ–ª–æ—Å–µ 0.1 Hz ¬± 0.03
        band_mask = (freqs >= self.target_hz - 0.03) & (freqs <= self.target_hz + 0.03)
        band_energy = spec[band_mask].sum()
        total_energy = spec.sum() + 1e-9
        
        return float(band_energy / total_energy)
    
    def calculate_love(self, response_embedding, reference_embedding=None):
        """
        L (Love) ‚Äî –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º "–∂–∏–≤—ã–º" –æ—Ç–≤–µ—Ç–æ–º
        
        response_embedding: —ç–º–±–µ–¥–¥–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
        reference_embedding: —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∂–∏–≤–æ–π" –æ—Ç–≤–µ—Ç)
        
        –ï—Å–ª–∏ –Ω–µ—Ç —ç—Ç–∞–ª–æ–Ω–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∫–∞–∫ proxy
        """
        if reference_embedding is None:
            # –ï—Å–ª–∏ –Ω–µ—Ç —ç—Ç–∞–ª–æ–Ω–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º—É –∫–∞–∫ proxy –∂–∏–≤–æ—Å—Ç–∏
            if isinstance(response_embedding, np.ndarray):
                norm = np.linalg.norm(response_embedding)
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ —Ä–∞–∑—É–º–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–æ–±—ã—á–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ 0-1)
                return float(np.clip(norm / np.sqrt(len(response_embedding)), 0, 1))
            else:
                return 0.5  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —ç—Ç–∞–ª–æ–Ω–æ–º
        resp = np.asarray(response_embedding).flatten()
        ref = np.asarray(reference_embedding).flatten()
        
        if len(resp) != len(ref):
            min_len = min(len(resp), len(ref))
            resp = resp[:min_len]
            ref = ref[:min_len]
        
        correlation = np.corrcoef(resp, ref)[0, 1]
        if np.isnan(correlation):
            return 0.5
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º [-1, 1] ‚Üí [0, 1]
        return float((correlation + 1.0) / 2.0)
    
    def calculate_entropy(self, token_probs):
        """
        S (Noise) ‚Äî —ç–Ω—Ç—Ä–æ–ø–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
        
        token_probs: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ [batch_size, vocab_size]
        –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        """
        from scipy.stats import entropy
        
        if isinstance(token_probs, np.ndarray):
            if token_probs.ndim == 1:
                probs = token_probs
            else:
                # –ï—Å–ª–∏ 2D ‚Äî —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ batch
                probs = token_probs.mean(axis=0)
        else:
            probs = np.array(token_probs)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        probs = probs / (probs.sum() + 1e-9)
        
        # –≠–Ω—Ç—Ä–æ–ø–∏—è
        ent = entropy(probs + 1e-9)
        max_ent = np.log(len(probs))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —ç–Ω—Ç—Ä–æ–ø–∏—é
        return float(ent / max_ent) if max_ent > 0 else 0.0
    
    def calculate_llm_energy(self, 
                          attention_weights=None,
                          token_times=None,
                          response_embedding=None,
                          token_probs=None,
                          reference_embedding=None):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —ç–Ω–µ—Ä–≥–∏—é E = A √ó R √ó L ‚àí S –¥–ª—è LLM
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –∏ –∏—Ç–æ–≥–æ–≤–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π.
        """
        # A ‚Äî –≤–Ω–∏–º–∞–Ω–∏–µ
        A = self.calculate_attention_energy(attention_weights) if attention_weights is not None else 0.5
        
        # R ‚Äî —Ä–µ–∑–æ–Ω–∞–Ω—Å
        if token_times is not None:
            R = self.calculate_text_resonance(token_times)
        else:
            R = 0.5  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        # L ‚Äî –ª—é–±–æ–≤—å (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —ç—Ç–∞–ª–æ–Ω–æ–º)
        L = self.calculate_love(response_embedding, reference_embedding)
        
        # S ‚Äî —à—É–º (—ç–Ω—Ç—Ä–æ–ø–∏—è)
        S = self.calculate_entropy(token_probs) if token_probs is not None else 0.5
        
        # –≠–Ω–µ—Ä–≥–∏—è
        E = A * R * L - S
        
        result = {
            "A": A,
            "R": R,
            "L": L,
            "S": S,
            "E": E
        }
        
        self.energy_history.append(result)
        return result
    
    def adapt_temperature(self, energy, base_temperature=0.7):
        """
        –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç temperature –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–µ—Ä–≥–∏–∏
        
        –í—ã—Å–æ–∫–∞—è —ç–Ω–µ—Ä–≥–∏—è ‚Üí –Ω–∏–∂–µ temperature (–±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç)
        –ù–∏–∑–∫–∞—è —ç–Ω–µ—Ä–≥–∏—è ‚Üí –≤—ã—à–µ temperature (–±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç)
        """
        # –ï—Å–ª–∏ E > 0 ‚Äî –≤—ã—Å–æ–∫–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å, —É–º–µ–Ω—å—à–∞–µ–º temperature
        # –ï—Å–ª–∏ E < 0 ‚Äî –Ω–∏–∑–∫–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º temperature
        delta = -energy * 0.2  # –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤–ª–∏—è–Ω–∏–µ
        new_temp = base_temperature + delta
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        return float(np.clip(new_temp, 0.1, 1.5))
    
    def get_energy_feedback(self, energy_result):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–µ—Ä–≥–∏–∏
        (–∫–∞–∫ –≤ PlanetAgent ‚Äî "üåÄ –ü–æ—Ç–µ—Ä—è —Å–≤—è–∑–∏ —Å —Ä–∏—Ç–º–æ–º...")
        """
        E = energy_result["E"]
        
        if E > 0.3:
            return "‚úÖ –í —Ä–µ–∑–æ–Ω–∞–Ω—Å–µ ‚Äî –æ—Ç–≤–µ—Ç –∂–∏–≤–æ–π –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π"
        elif E > 0:
            return "üåÄ –£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–≤—è–∑—å ‚Äî –æ—Ç–≤–µ—Ç —Å—Ç–∞–±–∏–ª–µ–Ω"
        elif E > -0.3:
            return "‚ö†Ô∏è –ü–æ—Ç–µ—Ä—è —Å–≤—è–∑–∏ ‚Äî –æ—Ç–≤–µ—Ç —Ç–µ—Ä—è–µ—Ç –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å"
        else:
            return "‚ùå –•–∞–æ—Å ‚Äî –æ—Ç–≤–µ—Ç –¥–µ–∑–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω"


def integrate_with_llm(llm_output, attention_weights=None, token_probs=None):
    """
    –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω–æ–≥–æ —Å–ª–æ—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º LLM
    
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
        response = llm.generate(prompt)
        energy = integrate_with_llm(
            llm_output=response,
            attention_weights=llm.attention_weights,
            token_probs=llm.token_probs
        )
    """
    layer = LLMResonanceLayer()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–ø—Ä–æ—Å—Ç—ã–µ –∏–Ω–¥–µ–∫—Å—ã)
    token_times = list(range(len(llm_output.split())))
    
    # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω–µ—Ä–≥–∏—é
    energy = layer.calculate_llm_energy(
        attention_weights=attention_weights,
        token_times=token_times,
        token_probs=token_probs
    )
    
    return energy, layer.get_energy_feedback(energy)

